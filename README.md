# ğŸ  RoomEase MVP

RoomEase is an AI-powered roommate and apartment recommendation app built with **Streamlit**, **Gemini 2 Flash**, and **local LLaMA (via LM Studio)**. It matches students with compatible roommates and ideal apartments in Madrid based on preferences, lifestyle, and budget.

---

## âœ¨ Features

* ğŸ’¬ **Conversational interface** â€“ Streamlit chatbot guides the user through 10 personality questions.
* ğŸ§  **AI-based roommate matching** â€“ Uses local embeddings and Gemini Flash 2 for personality compatibility.
* ğŸ¢ **Apartment finder** â€“ Combines semantic search, reranking, and structured filters via Gemini.
* ğŸ” **RAG architecture** â€“ Uses ChromaDB + SentenceTransformer embeddings for student and apartment indexing.
* âš¡ **Local + cloud hybrid** â€“ Runs Gemini API in combination with a local LLaMA model served through LM Studio.

---

## ğŸ§± Tech Stack

* **Frontend:** Streamlit (Python)
* **LLMs:** LLaMA 3B Instruct (local via LM Studio), Gemini Flash 2 (Google Generative AI)
* **Vector DB:** ChromaDB (Persistent client)
* **Embeddings:** SentenceTransformer (`all-MiniLM-L6-v2`)
* **Re-ranking:** CrossEncoder (`ms-marco-MiniLM-L-6-v2`)
* **PDF Parsing:** PyPDF (student metadata extraction)

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Prerequisites

* Python â‰¥ 3.10
* [LM Studio](https://lmstudio.ai/) installed and running
* Download **LLaMA 3B Instruct** model inside LM Studio
* A valid **Gemini API key** for Googleâ€™s Generative AI

### 2ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/ARM-02/roomease-mvp.git
cd roomease-mvp
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## âš™ï¸ Environment Setup

### 1ï¸âƒ£ Start LM Studio Server

1. Open **LM Studio**
2. Download and load **LLaMA 3B Instruct** model
3. Start a **local API server** at port **1234**

   * The endpoint should look like: `http://127.0.0.1:1234/v1/chat/completions`

### 2ï¸âƒ£ Set Gemini API Key

```bash
export GEMINI_API_KEY="your_gemini_flash2_api_key"
```

*(For Windows PowerShell: `$env:GEMINI_API_KEY="your_gemini_flash2_api_key"`)*

---

## â–¶ï¸ Running the App

Once LM Studio and the environment are set up:

```bash
streamlit run app.py
```

Then open the Streamlit link (usually `http://localhost:8501`) in your browser.

---

## ğŸ—‚ï¸ Project Structure

```
roomease-mvp/
â”œâ”€â”€ app.py                       # Streamlit front-end chatbot
â”œâ”€â”€ rag_backend.py               # Core logic for apartment & roommate recommendations
â”œâ”€â”€ extract_students_metadata.py # Extracts structured data from student PDFs via LLM
â”œâ”€â”€ embed_index.py               # Embeds apartment & student data into ChromaDB
â”œâ”€â”€ apartment_description_summarizer.py # Summarizes Idealista listings via local LLM
â”œâ”€â”€ chroma_store/                # Persistent ChromaDB collections
â”œâ”€â”€ data/                        # Datasets (PDFs, CSVs)
â””â”€â”€ requirements.txt             # Dependencies
```

---

## ğŸ§ª Example Workflow

1. **Index apartments:**

   ```bash
   python embed_index.py --csv data/available_apartments.csv --reset-apartments
   ```
2. **Index student profiles:**

   ```bash
   python extract_students_metadata.py --pdf data/student_profiles.pdf --reset
   ```
3. **Run the chat app:**

   ```bash
   streamlit run app.py
   ```

---

## ğŸ§  Architecture Overview

* **LM Studio (LLaMA)** â†’ Summarizes long apartment descriptions locally.
* **Gemini Flash 2** â†’ Parses user queries, filters data, and scores compatibility.
* **ChromaDB** â†’ Stores embeddings for apartments and students.
* **SentenceTransformer + CrossEncoder** â†’ Handles retrieval and reranking.

---

### ğŸ§© Quick TL;DR

1. Download LLM Studio â†’ Load LLaMA 3B Instruct â†’ Start server on port 1234
2. `export GEMINI_API_KEY=...`
3. `streamlit run app.py`
   âœ… Thatâ€™s it â€” RoomEase is live!
